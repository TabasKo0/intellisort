{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "84a14034",
   "metadata": {},
   "source": [
    "# IntelliSort - Waste Classification Training\n",
    "\n",
    "## Overview\n",
    "This notebook trains a YOLOv8s-cls model to classify waste into 7 categories:\n",
    "- **Recyclables:** Plastic, Glass, Metal, Paper, Cardboard\n",
    "- **Compost:** Organic\n",
    "- **Landfill:** Trash\n",
    "\n",
    "---\n",
    "\n",
    "## Training Pipeline\n",
    "1. **Data Preparation** - Organize and merge datasets\n",
    "2. **Model Training** - Train YOLOv8s-cls (80 epochs, ~4 hours)\n",
    "3. **Evaluation** - Test accuracy and per-class metrics\n",
    "\n",
    "---\n",
    "\n",
    "## Prerequisites\n",
    "- **GPU:** NVIDIA with 6GB+ VRAM (CUDA 11.8+)\n",
    "- **Datasets:** \n",
    "  - Dataset 1: `data/waste_classification/dataset/` (30 classes)\n",
    "  -https://www.kaggle.com/datasets/alistairking/recyclable-and-household-waste-classification\n",
    "  - Dataset 2: `data/waste_simple/DATASET/` (Organic/Recyclable)\n",
    "  -https://www.kaggle.com/datasets/techsash/waste-classification-data\n",
    "- **Packages:** `ultralytics`, `torch`, `numpy<2`, `opencv-python`\n",
    "\n",
    "---\n",
    "\n",
    "## Getting Started\n",
    "Run cells sequentially. Total runtime: ~5-6 hours.\n",
    "\n",
    "---\n",
    "\n",
    "# 1. Setup & Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5beb4fde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working directory: f:\\shiii\\multidiciplinary\\intellisort\n",
      "Setup complete\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "import json\n",
    "import random\n",
    "from pathlib import Path\n",
    "from collections import Counter\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "if 'model_work' in os.getcwd():\n",
    "    os.chdir('..')\n",
    "\n",
    "print(f\"Working directory: {os.getcwd()}\")\n",
    "print(\"Setup complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9d653b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "CLASS_MAPPING = {\n",
    "    'plastic': [\n",
    "        'plastic_cup_lids',\n",
    "        'plastic_detergent_bottles',\n",
    "        'plastic_food_containers',\n",
    "        'plastic_shopping_bags',\n",
    "        'plastic_soda_bottles',\n",
    "        'plastic_straws',\n",
    "        'plastic_water_bottles',\n",
    "        'disposable_plastic_cutlery',\n",
    "        'plastic_film',\n",
    "    ],\n",
    "    \n",
    "    'glass': [\n",
    "        'glass_beverage_bottles',\n",
    "        'glass_cosmetic_containers',\n",
    "        'glass_food_jars',\n",
    "    ],\n",
    "    \n",
    "    'metal': [\n",
    "        'aerosol_cans',\n",
    "        'aluminum_food_cans',\n",
    "        'aluminum_soda_cans',\n",
    "        'metal_bottle_caps',\n",
    "    ],\n",
    "    \n",
    "    'paper': [\n",
    "        'magazines',\n",
    "        'newspaper',\n",
    "        'office_paper',\n",
    "        'paper_cups',\n",
    "    ],\n",
    "    \n",
    "    'cardboard': [\n",
    "        'cardboard_boxes',\n",
    "        'cardboard_packaging',\n",
    "    ],\n",
    "    \n",
    "    'organic': [\n",
    "        'coffee_grounds',\n",
    "        'eggshells',\n",
    "        'food_waste',\n",
    "    ],\n",
    "    \n",
    "    'trash': [\n",
    "        'styrofoam_food_containers',\n",
    "        'clothing',\n",
    "        'shoes',\n",
    "    ]\n",
    "}\n",
    "\n",
    "DISPOSAL_INFO = {\n",
    "    'plastic': {\n",
    "        'disposal': 'Recyclable',\n",
    "        'bin_color': 'Blue/Yellow',\n",
    "        'tip': 'Rinse containers and check recycling number (1, 2, 5 typically accepted)'\n",
    "    },\n",
    "    'glass': {\n",
    "        'disposal': 'Recyclable',\n",
    "        'bin_color': 'Green/Blue',\n",
    "        'tip': 'Remove caps, rinse thoroughly. Glass can be recycled infinitely!'\n",
    "    },\n",
    "    'metal': {\n",
    "        'disposal': 'Recyclable',\n",
    "        'bin_color': 'Blue',\n",
    "        'tip': 'Rinse cans and crush to save space'\n",
    "    },\n",
    "    'paper': {\n",
    "        'disposal': 'Recyclable',\n",
    "        'bin_color': 'Blue',\n",
    "        'tip': 'Keep dry and clean. Remove any plastic coating'\n",
    "    },\n",
    "    'cardboard': {\n",
    "        'disposal': 'Recyclable',\n",
    "        'bin_color': 'Blue',\n",
    "        'tip': 'Flatten boxes. Remove tape and labels if possible'\n",
    "    },\n",
    "    'organic': {\n",
    "        'disposal': 'Compost',\n",
    "        'bin_color': 'Brown/Green',\n",
    "        'tip': 'Great for composting! Creates nutrient-rich soil'\n",
    "    },\n",
    "    'trash': {\n",
    "        'disposal': 'Landfill',\n",
    "        'bin_color': 'Black/Gray',\n",
    "        'tip': 'Cannot be recycled. Consider reducing usage'\n",
    "    }\n",
    "}\n",
    "\n",
    "Path('model_work').mkdir(exist_ok=True)\n",
    "with open('model_work/class_mapping.json', 'w') as f:\n",
    "    json.dump({'mapping': CLASS_MAPPING, 'disposal': DISPOSAL_INFO}, f, indent=2)\n",
    "\n",
    "print(f\"Defined {len(CLASS_MAPPING)} custom categories\")\n",
    "print(f\"Mapped {sum(len(v) for v in CLASS_MAPPING.values())} original classes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ae3ef6d",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# 6. Merge Datasets into Combined Dataset\n",
    "\n",
    "Combines both datasets and maps to 7 final categories.\n",
    "\n",
    "## Input:\n",
    "- **Dataset 1:** `data/waste_classification/organized/` (30 classes)\n",
    "- **Dataset 2:** `data/waste_simple/DATASET/` (Organic/Recyclable)\n",
    "\n",
    "## Output:\n",
    "- **Combined:** `data/combined_dataset/` (7 classes)\n",
    "\n",
    "## Process:\n",
    "1. Maps 30 classes ‚Üí 7 categories\n",
    "2. Adds Dataset 2 organic images ‚Üí `organic/` class\n",
    "3. Adds Dataset 2 recyclable images ‚Üí `plastic/` class\n",
    "4. Prefixes filenames to avoid conflicts (`d1_`, `d2_`)\n",
    "5. Saves config to `model_work/dataset_config.pkl`\n",
    "\n",
    "## Expected Final Dataset:\n",
    "| Class | Train | Val | Test | Total |\n",
    "|-------|-------|-----|------|-------|\n",
    "| cardboard | 496 | 111 | 236 | 843 |\n",
    "| glass | 744 | 0 | 354 | 1,098 |\n",
    "| metal | 744 | 0 | 354 | 1,098 |\n",
    "| organic | 13,309 | 0 | 354 | 13,663 |\n",
    "| paper | 992 | 0 | 472 | 1,464 |\n",
    "| plastic | 11,983 | 0 | 944 | 12,927 |\n",
    "| trash | 744 | 0 | 354 | 1,098 |\n",
    "| **TOTAL** | **29,012** | **5,607** | **3,068** | **37,687** |\n",
    "\n",
    "‚ö†Ô∏è **Note:** Dataset is imbalanced (organic: 46%, plastic: 41%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82676dc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "import random\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "\n",
    "dataset1_raw = Path('data/waste_classification/dataset')\n",
    "dataset1_organized = Path('data/waste_classification/organized')\n",
    "\n",
    "\n",
    "print(\"ORGANIZING DATASET 1\")\n",
    "\n",
    "\n",
    "if not dataset1_raw.exists():\n",
    "    print(f\"Raw dataset not found at: {dataset1_raw}\")\n",
    "    print(\"   Make sure you to have dataset folder\")\n",
    "else:\n",
    "    print(f\"Found raw dataset: {dataset1_raw}\\n\")\n",
    "    \n",
    "    class_folders = sorted([d for d in dataset1_raw.iterdir() if d.is_dir()])\n",
    "    print(f\"Found {len(class_folders)} class folders\\n\")\n",
    "    \n",
    "    for split in ['train', 'val', 'test']:\n",
    "        for cls_folder in class_folders:\n",
    "            (dataset1_organized / split / cls_folder.name).mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    print(\"Splitting images into train/val/test (70/15/15)...\\n\")\n",
    "    \n",
    "    stats = {'train': 0, 'val': 0, 'test': 0}\n",
    "    \n",
    "    for cls_folder in tqdm(class_folders, desc=\"Processing classes\"):\n",
    "        cls_name = cls_folder.name\n",
    "        \n",
    "        images = list(cls_folder.glob('*.jpg')) + \\\n",
    "                 list(cls_folder.glob('*.png')) + \\\n",
    "                 list(cls_folder.glob('*.jpeg')) + \\\n",
    "                 list(cls_folder.glob('*.JPG')) + \\\n",
    "                 list(cls_folder.glob('*.PNG'))\n",
    "        \n",
    "        if len(images) == 0:\n",
    "            continue\n",
    "        \n",
    "        random.seed(42)\n",
    "        random.shuffle(images)\n",
    "        \n",
    "        if len(images) >= 10:\n",
    "            # 70-15-15 split\n",
    "            train_idx = int(len(images) * 0.7)\n",
    "            val_idx = int(len(images) * 0.85)\n",
    "            \n",
    "            train_imgs = images[:train_idx]\n",
    "            val_imgs = images[train_idx:val_idx]\n",
    "            test_imgs = images[val_idx:]\n",
    "        elif len(images) >= 3:\n",
    "            train_idx = int(len(images) * 0.7)\n",
    "            train_imgs = images[:train_idx]\n",
    "            val_imgs = images[train_idx:]\n",
    "            test_imgs = []\n",
    "        else:\n",
    "            train_imgs = images\n",
    "            val_imgs = []\n",
    "            test_imgs = []\n",
    "        \n",
    "        for img in train_imgs:\n",
    "            dest = dataset1_organized / 'train' / cls_name / img.name\n",
    "            shutil.copy2(img, dest)\n",
    "            stats['train'] += 1\n",
    "        \n",
    "        for img in val_imgs:\n",
    "            dest = dataset1_organized / 'val' / cls_name / img.name\n",
    "            shutil.copy2(img, dest)\n",
    "            stats['val'] += 1\n",
    "        \n",
    "        for img in test_imgs:\n",
    "            dest = dataset1_organized / 'test' / cls_name / img.name\n",
    "            shutil.copy2(img, dest)\n",
    "            stats['test'] += 1\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"DATASET 1 ORGANIZED!\")\n",
    "    \n",
    "    print(f\"\\nTrain: {stats['train']:,} images\")\n",
    "    print(f\"Val:   {stats['val']:,} images\")\n",
    "    print(f\"Test:  {stats['test']:,} images\")\n",
    "    print(f\"Total: {sum(stats.values()):,} images\")\n",
    "    \n",
    "    print(f\"\\nOrganized dataset saved to:\")\n",
    "    print(f\"   {dataset1_organized}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca5d4ddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "import random\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "\n",
    "dataset1_raw = Path('data/waste_classification/dataset')\n",
    "dataset1_organized = Path('data/waste_classification/organized')\n",
    "\n",
    "\n",
    "print(\"ORGANIZING DATASET 1 - WITH SUBFOLDERS\")\n",
    "\n",
    "if not dataset1_raw.exists():\n",
    "    print(f\"Raw dataset not found!\")\n",
    "else:\n",
    "    print(f\"Source: {dataset1_raw}\")\n",
    "    print(f\"Target: {dataset1_organized}\\n\")\n",
    "    \n",
    "    class_folders = sorted([d for d in dataset1_raw.iterdir() if d.is_dir()])\n",
    "    print(f\"Found {len(class_folders)} class folders\\n\")\n",
    "    \n",
    "    print(\"Creating directories...\")\n",
    "    for split in ['train', 'val', 'test']:\n",
    "        for cls_folder in class_folders:\n",
    "            (dataset1_organized / split / cls_folder.name).mkdir(parents=True, exist_ok=True)\n",
    "    print(\"Directories created\\n\")\n",
    "    \n",
    "    stats = {'train': 0, 'val': 0, 'test': 0}\n",
    "    \n",
    "    print(\"Copying images from subfolders...\\n\")\n",
    "    \n",
    "    for cls_folder in tqdm(class_folders, desc=\"Processing classes\"):\n",
    "        cls_name = cls_folder.name\n",
    "        \n",
    "        images = []\n",
    "        \n",
    "        subfolders = [d for d in cls_folder.iterdir() if d.is_dir()]\n",
    "        \n",
    "        if len(subfolders) > 0:\n",
    "            for subfolder in subfolders:\n",
    "                for ext in ['*.jpg', '*.jpeg', '*.png', '*.JPG', '*.JPEG', '*.PNG']:\n",
    "                    images.extend(list(subfolder.glob(ext)))\n",
    "        else:\n",
    "            for ext in ['*.jpg', '*.jpeg', '*.png', '*.JPG', '*.JPEG', '*.PNG']:\n",
    "                images.extend(list(cls_folder.glob(ext)))\n",
    "        \n",
    "        if len(images) == 0:\n",
    "            continue\n",
    "        \n",
    "        random.seed(42)\n",
    "        random.shuffle(images)\n",
    "        \n",
    "        if len(images) >= 10:\n",
    "            train_idx = int(len(images) * 0.7)\n",
    "            val_idx = int(len(images) * 0.85)\n",
    "            train_imgs = images[:train_idx]\n",
    "            val_imgs = images[train_idx:val_idx]\n",
    "            test_imgs = images[val_idx:]\n",
    "        elif len(images) >= 3:\n",
    "            train_idx = int(len(images) * 0.7)\n",
    "            train_imgs = images[:train_idx]\n",
    "            val_imgs = images[train_idx:]\n",
    "            test_imgs = []\n",
    "        else:\n",
    "            train_imgs = images\n",
    "            val_imgs = []\n",
    "            test_imgs = []\n",
    "        \n",
    "        for img in train_imgs:\n",
    "            dest = dataset1_organized / 'train' / cls_name / img.name\n",
    "            shutil.copy2(img, dest)\n",
    "            stats['train'] += 1\n",
    "        \n",
    "        for img in val_imgs:\n",
    "            dest = dataset1_organized / 'val' / cls_name / img.name\n",
    "            shutil.copy2(img, dest)\n",
    "            stats['val'] += 1\n",
    "        \n",
    "        for img in test_imgs:\n",
    "            dest = dataset1_organized / 'test' / cls_name / img.name\n",
    "            shutil.copy2(img, dest)\n",
    "            stats['test'] += 1\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"ORGANIZATION COMPLETE!\")\n",
    "    \n",
    "    print(f\"\\nTrain: {stats['train']:,} images\")\n",
    "    print(f\"Val:   {stats['val']:,} images\")\n",
    "    print(f\"Test:  {stats['test']:,} images\")\n",
    "    print(f\"Total: {sum(stats.values()):,} images\")\n",
    "    \n",
    "    if sum(stats.values()) > 0:\n",
    "        print(f\"\\n‚úÖ Files copied successfully!\")\n",
    "    else:\n",
    "        print(f\"\\n‚ùå No files copied - check dataset structure\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85aeab93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "VERIFICATION\n",
      "======================================================================\n",
      "\n",
      "TRAIN:\n",
      "   Folders: 30\n",
      "   Images:  7,440\n",
      "   Samples:\n",
      "      aerosol_cans: 248 images\n",
      "      aluminum_food_cans: 248 images\n",
      "      aluminum_soda_cans: 248 images\n",
      "\n",
      "VAL:\n",
      "   Folders: 30\n",
      "   Images:  3,570\n",
      "   Samples:\n",
      "      aerosol_cans: 119 images\n",
      "      aluminum_food_cans: 119 images\n",
      "      aluminum_soda_cans: 119 images\n",
      "\n",
      "TEST:\n",
      "   Folders: 30\n",
      "   Images:  3,540\n",
      "   Samples:\n",
      "      aerosol_cans: 118 images\n",
      "      aluminum_food_cans: 118 images\n",
      "      aluminum_soda_cans: 118 images\n",
      "\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "organized_path = Path('../data/waste_classification/organized')\n",
    "\n",
    "\n",
    "print(\"VERIFICATION\")\n",
    "\n",
    "\n",
    "for split in ['train', 'val', 'test']:\n",
    "    split_path = organized_path / split\n",
    "    \n",
    "    if not split_path.exists():\n",
    "        print(f\"\\n{split}: Not found\")\n",
    "        continue\n",
    "    \n",
    "    folders = sorted([d for d in split_path.iterdir() if d.is_dir()])\n",
    "    total_images = sum(len(list(f.glob('*.jpg'))) + len(list(f.glob('*.png'))) \n",
    "                      for f in folders)\n",
    "    \n",
    "    print(f\"\\n{split.upper()}:\")\n",
    "    print(f\"   Folders: {len(folders)}\")\n",
    "    print(f\"   Images:  {total_images:,}\")\n",
    "    \n",
    "    if len(folders) > 0:\n",
    "        print(f\"   Samples:\")\n",
    "        for folder in folders[:3]:\n",
    "            img_count = len(list(folder.glob('*.jpg'))) + len(list(folder.glob('*.png')))\n",
    "            print(f\"      {folder.name}: {img_count} images\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2de96457",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "MERGING DATASETS INTO COMBINED\n",
      "======================================================================\n",
      "\n",
      "üìã Checking datasets...\n",
      "   Dataset 1 (organized): ‚ùå\n",
      "   Dataset 2 (simple):    ‚ùå\n",
      "\n",
      "‚ùå Dataset 1 not organized yet! Run organization cell first.\n",
      "\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "import shutil\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "\n",
    "dataset1_organized = Path('data/waste_classification/organized')\n",
    "dataset2_full = Path('data/waste_simple/DATASET')\n",
    "combined_path = Path('data/combined_dataset')\n",
    "\n",
    "\n",
    "print(\"MERGING DATASETS INTO COMBINED\")\n",
    "\n",
    "\n",
    "print(\"\\nChecking datasets...\")\n",
    "d1_exists = dataset1_organized.exists() and (dataset1_organized / 'train').exists()\n",
    "d2_exists = dataset2_full.exists()\n",
    "\n",
    "print(f\"   Dataset 1 (organized): {'‚úÖ' if d1_exists else '‚ùå'}\")\n",
    "print(f\"   Dataset 2 (simple):    {'‚úÖ' if d2_exists else '‚ùå'}\")\n",
    "\n",
    "if not d1_exists:\n",
    "    print(\"\\nDataset 1 not organized yet! Run organization cell first.\")\n",
    "else:\n",
    "    # Remove old combined dataset if exists\n",
    "    if combined_path.exists():\n",
    "        print(f\"\\nRemoving old combined dataset...\")\n",
    "        shutil.rmtree(combined_path)\n",
    "        print(\"   ‚úÖ Removed\")\n",
    "    \n",
    "    print(f\"\\nCreating combined dataset structure...\\n\")\n",
    "    \n",
    "    for split in ['train', 'val', 'test']:\n",
    "        for category in CLASS_MAPPING.keys():\n",
    "            (combined_path / split / category).mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    print(\"Folders created\\n\")\n",
    "    \n",
    "    stats = {cat: {'train': 0, 'val': 0, 'test': 0} for cat in CLASS_MAPPING.keys()}\n",
    "    \n",
    "    reverse_map = {}\n",
    "    for custom_cat, orig_classes in CLASS_MAPPING.items():\n",
    "        for orig in orig_classes:\n",
    "            reverse_map[orig] = custom_cat\n",
    "    \n",
    "    \n",
    "    print(\"PART 1: PROCESSING DATASET 1\")\n",
    "    \n",
    "    \n",
    "    for split in ['train', 'val', 'test']:\n",
    "        split_path = dataset1_organized / split\n",
    "        \n",
    "        if not split_path.exists():\n",
    "            print(f\"\\n{split} folder not found, skipping\")\n",
    "            continue\n",
    "        \n",
    "        print(f\"\\nProcessing {split}...\")\n",
    "        \n",
    "        class_folders = sorted([d for d in split_path.iterdir() if d.is_dir()])\n",
    "        \n",
    "        for cls_folder in tqdm(class_folders, desc=f\"  {split}\"):\n",
    "            orig_class = cls_folder.name\n",
    "            \n",
    "            if orig_class not in reverse_map:\n",
    "                continue\n",
    "            \n",
    "            custom_cat = reverse_map[orig_class]\n",
    "            \n",
    "            images = list(cls_folder.glob('*.jpg')) + \\\n",
    "                     list(cls_folder.glob('*.png')) + \\\n",
    "                     list(cls_folder.glob('*.jpeg'))\n",
    "            \n",
    "            for img in images:\n",
    "                dest_name = f\"d1_{orig_class}_{img.name}\"\n",
    "                dest = combined_path / split / custom_cat / dest_name\n",
    "                \n",
    "                try:\n",
    "                    shutil.copy2(img, dest)\n",
    "                    stats[custom_cat][split] += 1\n",
    "                except Exception as e:\n",
    "                    print(f\"\\nError copying {img.name}: {e}\")\n",
    "    \n",
    "    if d2_exists:\n",
    "        print(\"\\n\" + \"=\"*70)\n",
    "        print(\"PART 2: PROCESSING DATASET 2\")\n",
    "        \n",
    "        \n",
    "        train_path = dataset2_full / 'TRAIN'\n",
    "        if train_path.exists():\n",
    "            print(f\"\\nüì¶ Processing TRAIN...\")\n",
    "            \n",
    "            o_path = train_path / 'O'\n",
    "            if o_path.exists():\n",
    "                images = list(o_path.glob('*.jpg')) + list(o_path.glob('*.png'))\n",
    "                for img in tqdm(images, desc=\"  Organic\"):\n",
    "                    dest = combined_path / 'train' / 'organic' / f\"d2_o_{img.name}\"\n",
    "                    shutil.copy2(img, dest)\n",
    "                    stats['organic']['train'] += 1\n",
    "            \n",
    "            r_path = train_path / 'R'\n",
    "            if r_path.exists():\n",
    "                images = list(r_path.glob('*.jpg')) + list(r_path.glob('*.png'))\n",
    "                for img in tqdm(images, desc=\"  Recyclable\"):\n",
    "                    dest = combined_path / 'train' / 'plastic' / f\"d2_r_{img.name}\"\n",
    "                    shutil.copy2(img, dest)\n",
    "                    stats['plastic']['train'] += 1\n",
    "        \n",
    "        test_path = dataset2_full / 'TEST'\n",
    "        if test_path.exists():\n",
    "            print(f\"\\nüì¶ Processing TEST...\")\n",
    "            \n",
    "            o_path = test_path / 'O'\n",
    "            if o_path.exists():\n",
    "                images = list(o_path.glob('*.jpg')) + list(o_path.glob('*.png'))\n",
    "                for img in tqdm(images, desc=\"  Organic\"):\n",
    "                    dest = combined_path / 'val' / 'organic' / f\"d2_o_val_{img.name}\"\n",
    "                    shutil.copy2(img, dest)\n",
    "                    stats['organic']['val'] += 1\n",
    "            \n",
    "            r_path = test_path / 'R'\n",
    "            if r_path.exists():\n",
    "                images = list(r_path.glob('*.jpg')) + list(r_path.glob('*.png'))\n",
    "                for img in tqdm(images, desc=\"  Recyclable\"):\n",
    "                    dest = combined_path / 'val' / 'plastic' / f\"d2_r_val_{img.name}\"\n",
    "                    shutil.copy2(img, dest)\n",
    "                    stats['plastic']['val'] += 1\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"COMBINED DATASET STATISTICS\")\n",
    "    \n",
    "    print(f\"\\n{'Category':<12} {'Train':>8} {'Val':>8} {'Test':>8} {'Total':>8}\")\n",
    "    print(\"-\"*70)\n",
    "    \n",
    "    for cat in sorted(CLASS_MAPPING.keys()):\n",
    "        t = stats[cat]['train']\n",
    "        v = stats[cat]['val']\n",
    "        te = stats[cat]['test']\n",
    "        total = t + v + te\n",
    "        print(f\"{cat:<12} {t:>8,} {v:>8,} {te:>8,} {total:>8,}\")\n",
    "    \n",
    "    print(\"-\"*70)\n",
    "    \n",
    "    total_train = sum(s['train'] for s in stats.values())\n",
    "    total_val = sum(s['val'] for s in stats.values())\n",
    "    total_test = sum(s['test'] for s in stats.values())\n",
    "    grand_total = total_train + total_val + total_test\n",
    "    \n",
    "    print(f\"{'TOTAL':<12} {total_train:>8,} {total_val:>8,} {total_test:>8,} {grand_total:>8,}\")\n",
    "    \n",
    "    \n",
    "    import pickle\n",
    "    \n",
    "    config = {\n",
    "        'dataset_path': str(combined_path),\n",
    "        'num_classes': len(CLASS_MAPPING),\n",
    "        'class_names': list(CLASS_MAPPING.keys()),\n",
    "        'class_mapping': CLASS_MAPPING,\n",
    "        'disposal_info': DISPOSAL_INFO\n",
    "    }\n",
    "    \n",
    "    Path('model_work').mkdir(exist_ok=True)\n",
    "    with open('model_work/dataset_config.pkl', 'wb') as f:\n",
    "        pickle.dump(config, f)\n",
    "    \n",
    "    print(f\"\\nCombined dataset created!\")\n",
    "    print(f\"Location: {combined_path}\")\n",
    "    print(f\"Config saved: model_work/dataset_config.pkl\")\n",
    "    print(f\"\\nReady for training\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f39ce048",
   "metadata": {},
   "source": [
    "# Model Training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ee83c5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "INTELLISORT - TRAINING SETUP\n",
      "======================================================================\n",
      "\n",
      "üñ•Ô∏è Hardware:\n",
      "   ‚úÖ GPU: NVIDIA GeForce RTX 4050 Laptop GPU\n",
      "   CUDA: 11.8\n",
      "   Memory: 6.44 GB\n",
      "\n",
      "üìä Dataset:\n",
      "   Path: data\\combined_dataset\n",
      "   Classes: 7\n",
      "   Categories: plastic, glass, metal, paper, cardboard, organic, trash\n",
      "\n",
      "‚úÖ Setup complete - Ready to train!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "\n",
    "# Force NVIDIA GPU\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "os.environ['CUDA_DEVICE_ORDER'] = 'PCI_BUS_ID'\n",
    "\n",
    "import torch\n",
    "from ultralytics import YOLO\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Change to project root\n",
    "if 'model_work' in os.getcwd():\n",
    "    os.chdir('..')\n",
    "\n",
    "\n",
    "print(\"INTELLISORT - TRAINING SETUP\")\n",
    "\n",
    "\n",
    "# GPU Check\n",
    "print(\"\\nHardware:\")\n",
    "if torch.cuda.is_available():\n",
    "    device = 'cuda:0'\n",
    "    torch.cuda.set_device(0)\n",
    "    print(f\"   GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"   CUDA: {torch.version.cuda}\")\n",
    "    print(f\"   Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")\n",
    "else:\n",
    "    device = 'cpu'\n",
    "    print(f\"   CPU only - training will be very slow!\")\n",
    "\n",
    "# Load config\n",
    "with open('model_work/dataset_config.pkl', 'rb') as f:\n",
    "    config = pickle.load(f)\n",
    "\n",
    "dataset_path = Path(config['dataset_path'])\n",
    "num_classes = config['num_classes']\n",
    "class_names = config['class_names']\n",
    "\n",
    "print(f\"\\n Dataset:\")\n",
    "print(f\"   Path: {dataset_path}\")\n",
    "print(f\"   Classes: {num_classes}\")\n",
    "print(f\"   Categories: {', '.join(class_names)}\")\n",
    "\n",
    "# Get class counts for reference\n",
    "train_path = dataset_path / 'train'\n",
    "class_counts = {}\n",
    "for cat in class_names:\n",
    "    cat_path = train_path / cat\n",
    "    if cat_path.exists():\n",
    "        count = len(list(cat_path.glob('*.jpg'))) + len(list(cat_path.glob('*.png')))\n",
    "        class_counts[cat] = count\n",
    "\n",
    "globals()['class_counts'] = class_counts\n",
    "\n",
    "print(f\"\\nSetup complete - Ready to train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "366ad37c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "LOADING YOLO MODEL\n",
      "======================================================================\n",
      "\n",
      "‚úÖ YOLOv8s-cls loaded\n",
      "   Pre-trained on ImageNet\n",
      "   Model size: ~25MB\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"LOADING YOLO MODEL\")\n",
    "\n",
    "\n",
    "# Load YOLOv8s-cls\n",
    "model = YOLO('yolov8s-cls.pt')\n",
    "\n",
    "print(\"\\n‚úÖ YOLOv8s-cls loaded\")\n",
    "print(\"   Pre-trained on ImageNet\")\n",
    "print(\"   Model size: ~25MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2143cf58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "TRAINING CONFIGURATION\n",
      "======================================================================\n",
      "\n",
      "üìã Hyperparameters:\n",
      "   Epochs:           80\n",
      "   Batch size:       32\n",
      "   Image size:       224√ó224\n",
      "   Learning rate:    0.0005\n",
      "   Patience:         15 epochs\n",
      "   Checkpoints:      Every 10 epochs\n",
      "   Device:           cuda:0\n",
      "\n",
      "‚è±Ô∏è Time Estimate:\n",
      "   Training images:   29,012\n",
      "   Batches per epoch: 906\n",
      "   Time per epoch:    ~4.5 min\n",
      "   Max time (80 epochs): ~6.0 hours\n",
      "   Expected (early stop): ~4.2 hours\n",
      "\n",
      "‚ö†Ô∏è Dataset is imbalanced - will monitor per-class metrics\n",
      "\n",
      "‚úÖ Configuration ready!\n"
     ]
    }
   ],
   "source": [
    "# Optimized hyperparameters\n",
    "EPOCHS = 80\n",
    "BATCH_SIZE = 32\n",
    "IMAGE_SIZE = 224\n",
    "PATIENCE = 15\n",
    "LEARNING_RATE = 0.0005\n",
    "CHECKPOINT_FREQ = 10\n",
    "\n",
    "\n",
    "print(\"TRAINING CONFIGURATION\")\n",
    "\n",
    "\n",
    "print(f\"\\nüìã Hyperparameters:\")\n",
    "print(f\"   Epochs:           {EPOCHS}\")\n",
    "print(f\"   Batch size:       {BATCH_SIZE}\")\n",
    "print(f\"   Image size:       {IMAGE_SIZE}√ó{IMAGE_SIZE}\")\n",
    "print(f\"   Learning rate:    {LEARNING_RATE}\")\n",
    "print(f\"   Patience:         {PATIENCE} epochs\")\n",
    "print(f\"   Checkpoints:      Every {CHECKPOINT_FREQ} epochs\")\n",
    "print(f\"   Device:           {device}\")\n",
    "\n",
    "# Correct time estimation\n",
    "train_images = 29012\n",
    "batches_per_epoch = train_images // BATCH_SIZE  # 906 batches\n",
    "\n",
    "print(f\"\\n‚è±Ô∏è Time Estimate:\")\n",
    "print(f\"   Training images:   {train_images:,}\")\n",
    "print(f\"   Batches per epoch: {batches_per_epoch}\")\n",
    "\n",
    "if device == 'cuda:0':\n",
    "    seconds_per_batch = 0.3\n",
    "    minutes_per_epoch = (batches_per_epoch * seconds_per_batch) / 60\n",
    "    total_hours = (minutes_per_epoch * EPOCHS) / 60\n",
    "    expected_hours = (minutes_per_epoch * 55) / 60  # With early stopping\n",
    "    \n",
    "    print(f\"   Time per epoch:    ~{minutes_per_epoch:.1f} min\")\n",
    "    print(f\"   Max time (80 epochs): ~{total_hours:.1f} hours\")\n",
    "    print(f\"   Expected (early stop): ~{expected_hours:.1f} hours\")\n",
    "else:\n",
    "    print(f\"   ‚ö†Ô∏è CPU training would take 8-12 hours!\")\n",
    "\n",
    "print(f\"\\n‚ö†Ô∏è Dataset is imbalanced - will monitor per-class metrics\")\n",
    "print(\"\\n‚úÖ Configuration ready!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d903595",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "üöÄ STARTING TRAINING\n",
      "======================================================================\n",
      "\n",
      "Training on: NVIDIA GeForce RTX 4050 Laptop GPU\n",
      "Images: 29,012 train / 5,607 val / 3,068 test\n",
      "\n",
      "‚è≥ Estimated time: 3-4 hours\n",
      "üí° You can monitor GPU usage: nvidia-smi -l 1\n",
      "\n",
      "Ultralytics 8.4.11  Python-3.10.11 torch-2.1.2+cu118 CUDA:0 (NVIDIA GeForce RTX 4050 Laptop GPU, 6140MiB)\n",
      "\u001b[34m\u001b[1mengine\\trainer: \u001b[0magnostic_nms=False, amp=False, angle=1.0, augment=False, auto_augment=randaugment, batch=32, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=data\\combined_dataset, degrees=10, deterministic=True, device=0, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, end2end=None, epochs=80, erasing=0.4, exist_ok=True, fliplr=0.5, flipud=0.2, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=224, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.0005, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov8s-cls.pt, momentum=0.937, mosaic=0.0, multi_scale=0.0, name=waste_classifier, nbs=64, nms=False, opset=None, optimize=False, optimizer=Adam, overlap_mask=True, patience=15, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=model_work/runs, rect=False, resume=False, retina_masks=False, rle=1.0, save=True, save_conf=False, save_crop=False, save_dir=F:\\shiii\\multidiciplinary\\intellisort\\runs\\classify\\model_work\\runs\\waste_classifier, save_frames=False, save_json=False, save_period=10, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=classify, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=4, workspace=None\n",
      "\u001b[34m\u001b[1mtrain:\u001b[0m F:\\shiii\\multidiciplinary\\intellisort\\data\\combined_dataset\\train... found 29012 images in 7 classes  \n",
      "\u001b[34m\u001b[1mval:\u001b[0m F:\\shiii\\multidiciplinary\\intellisort\\data\\combined_dataset\\val... found 5607 images in 7 classes  \n",
      "\u001b[34m\u001b[1mtest:\u001b[0m F:\\shiii\\multidiciplinary\\intellisort\\data\\combined_dataset\\test... found 3068 images in 7 classes  \n",
      "Overriding model.yaml nc=1000 with nc=7\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       928  ultralytics.nn.modules.conv.Conv             [3, 32, 3, 2]                 \n",
      "  1                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  2                  -1  1     29056  ultralytics.nn.modules.block.C2f             [64, 64, 1, True]             \n",
      "  3                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  4                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  5                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  6                  -1  2    788480  ultralytics.nn.modules.block.C2f             [256, 256, 2, True]           \n",
      "  7                  -1  1   1180672  ultralytics.nn.modules.conv.Conv             [256, 512, 3, 2]              \n",
      "  8                  -1  1   1838080  ultralytics.nn.modules.block.C2f             [512, 512, 1, True]           \n",
      "  9                  -1  1    666887  ultralytics.nn.modules.head.Classify         [512, 7]                      \n",
      "YOLOv8s-cls summary: 56 layers, 5,089,703 parameters, 5,089,703 gradients, 12.6 GFLOPs\n",
      "Transferred 156/158 items from pretrained weights\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access  (ping: 0.10.1 ms, read: 156.154.5 MB/s, size: 58.5 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning F:\\shiii\\multidiciplinary\\intellisort\\data\\combined_dataset\\train... 29012 images, 0 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 29012/29012  0.0s\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access  (ping: 0.10.0 ms, read: 125.3270.0 MB/s, size: 38.0 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning F:\\shiii\\multidiciplinary\\intellisort\\data\\combined_dataset\\val... 5607 images, 0 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 5607/5607  0.0s\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m Adam(lr=0.0005, momentum=0.937) with parameter groups 26 weight(decay=0.0), 27 weight(decay=0.0005), 27 bias(decay=0.0)\n",
      "Image sizes 224 train, 224 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mF:\\shiii\\multidiciplinary\\intellisort\\runs\\classify\\model_work\\runs\\waste_classifier\u001b[0m\n",
      "Starting training for 80 epochs...\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\u001b[K       1/80      1.29G     0.5131         20        224: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 907/907 11.0it/s 1:23<0.1ss\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 88/88 8.5it/s 10.3s0.3s\n",
      "                   all       0.82      0.998\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\u001b[K       2/80       1.3G     0.3723         20        224: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 907/907 16.7it/s 54.3s<0.1s\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 88/88 21.6it/s 4.1s0.1s\n",
      "                   all      0.863      0.998\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\u001b[K       3/80       1.3G     0.3383         20        224: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 907/907 17.2it/s 52.8s<0.1s\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 88/88 15.7it/s 5.6s0.1s\n",
      "                   all      0.865      0.998\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\u001b[K       4/80       1.3G     0.3163         20        224: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 907/907 17.3it/s 52.3s<0.1s\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 88/88 22.9it/s 3.8s0.2s\n",
      "                   all      0.855      0.998\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\u001b[K       5/80       1.3G     0.2999         20        224: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 907/907 17.3it/s 52.5s<0.1s\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 88/88 25.4it/s 3.5s0.0s\n",
      "                   all      0.878      0.999\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\u001b[K       6/80       1.3G     0.2966         20        224: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 907/907 17.1it/s 53.1s<0.1s\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 88/88 26.1it/s 3.4s0.1s\n",
      "                   all      0.887      0.999\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\u001b[K       7/80       1.3G     0.2906         20        224: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 907/907 17.3it/s 52.4s<0.1s\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 88/88 25.0it/s 3.5s0.0s\n",
      "                   all      0.893      0.998\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\u001b[K       8/80       1.3G     0.2792         20        224: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 907/907 17.2it/s 52.9s<0.1s\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 88/88 25.8it/s 3.4s0.0s\n",
      "                   all      0.898      0.999\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\u001b[K       9/80       1.3G     0.2727         20        224: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 907/907 17.3it/s 52.4s<0.1s\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 88/88 27.1it/s 3.2s0.0s\n",
      "                   all      0.897      0.999\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\u001b[K      10/80       1.3G     0.2707         20        224: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 907/907 17.3it/s 52.4s<0.1s\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 88/88 27.0it/s 3.3s0.0s\n",
      "                   all        0.9      0.999\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\u001b[K      11/80       1.3G     0.2653         20        224: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 907/907 17.2it/s 52.7s<0.1s\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 88/88 26.7it/s 3.3s0.1s\n",
      "                   all      0.909      0.998\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\u001b[K      12/80       1.3G     0.2617         20        224: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 907/907 17.3it/s 52.3s<0.1s\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 88/88 21.7it/s 4.1s0.1s\n",
      "                   all      0.906      0.999\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\u001b[K      13/80       1.3G     0.2616         20        224: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 907/907 17.2it/s 52.6s<0.1s\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 88/88 27.0it/s 3.3s0.0s\n",
      "                   all        0.9      0.999\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\u001b[K      14/80       1.3G     0.2555         20        224: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 907/907 17.3it/s 52.5s<0.1s\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 88/88 27.0it/s 3.3s0.0s\n",
      "                   all      0.914      0.999\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\u001b[K      15/80       1.3G     0.2539         20        224: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 907/907 17.3it/s 52.4s<0.1s\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 88/88 20.9it/s 4.2s0.1s\n",
      "                   all      0.916      0.998\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\u001b[K      16/80       1.3G     0.2474         20        224: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 907/907 17.1it/s 53.0s<0.1s\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 88/88 24.9it/s 3.5s0.0s\n",
      "                   all      0.921      0.999\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\u001b[K      17/80       1.3G     0.2415         20        224: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 907/907 15.7it/s 57.7s<0.1s\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 88/88 7.0it/s 12.6s<0.3s\n",
      "                   all       0.92      0.999\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\u001b[K      18/80       1.3G     0.2443         20        224: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 907/907 17.0it/s 53.2s<0.1s\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 88/88 15.1it/s 5.8s0.2s\n",
      "                   all      0.922      0.999\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\u001b[K      19/80       1.3G     0.2372         20        224: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 907/907 17.1it/s 53.1s<0.1s\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 88/88 22.5it/s 3.9s0.1s\n",
      "                   all       0.92      0.999\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\u001b[K      20/80       1.3G     0.2398         20        224: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 907/907 17.3it/s 52.5s<0.1s\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 88/88 27.0it/s 3.3s0.0s\n",
      "                   all      0.915      0.999\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\u001b[K      21/80       1.3G     0.2339         20        224: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 907/907 17.0it/s 53.5s<0.2s\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 88/88 25.6it/s 3.4s0.1s\n",
      "                   all      0.924      0.999\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\u001b[K      22/80       1.3G      0.229         20        224: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 907/907 17.2it/s 52.8s<0.1s\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 88/88 25.2it/s 3.5s0.0s\n",
      "                   all      0.916      0.999\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\u001b[K      23/80       1.3G     0.2291         20        224: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 907/907 17.3it/s 52.4s<0.1s\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 88/88 26.0it/s 3.4s0.0s\n",
      "                   all      0.922      0.999\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\u001b[K      24/80       1.3G     0.2198         20        224: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 907/907 17.2it/s 52.8s<0.1s\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 88/88 25.9it/s 3.4s0.0s\n",
      "                   all      0.925      0.999\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\u001b[K      25/80       1.3G     0.2201         20        224: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 907/907 17.3it/s 52.5s<0.1s\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 88/88 25.9it/s 3.4s0.1s\n",
      "                   all      0.923      0.999\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\u001b[K      26/80       1.3G     0.2214         20        224: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 907/907 17.1it/s 52.9s<0.1s\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 88/88 26.5it/s 3.3s0.0s\n",
      "                   all      0.925      0.999\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\u001b[K      27/80       1.3G     0.2135         20        224: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 907/907 17.3it/s 52.5s<0.1s\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 88/88 25.9it/s 3.4s0.1s\n",
      "                   all      0.927          1\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\u001b[K      28/80       1.3G     0.2169         20        224: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 907/907 17.2it/s 52.8s<0.1s\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 88/88 26.2it/s 3.4s0.0s\n",
      "                   all      0.927          1\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\u001b[K      29/80       1.3G     0.2026         20        224: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 907/907 17.1it/s 52.9s<0.2s\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 88/88 26.2it/s 3.4s0.0s\n",
      "                   all      0.927          1\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\u001b[K      30/80       1.3G     0.2078         20        224: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 907/907 17.1it/s 53.2s<0.1s\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 88/88 26.4it/s 3.3s0.0s\n",
      "                   all      0.929          1\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\u001b[K      31/80       1.3G     0.2077         20        224: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 907/907 17.2it/s 52.6s<0.1s\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 88/88 26.3it/s 3.3s0.0s\n",
      "                   all       0.93          1\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\u001b[K      32/80       1.3G     0.2001         20        224: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 907/907 17.0it/s 53.3s<0.2s\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 88/88 24.2it/s 3.6s0.1s\n",
      "                   all      0.928          1\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\u001b[K      33/80       1.3G     0.2005         20        224: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 907/907 17.3it/s 52.5s<0.1s\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 88/88 24.8it/s 3.5s0.0s\n",
      "                   all      0.929          1\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\u001b[K      34/80       1.3G     0.1963         20        224: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 907/907 17.2it/s 52.7s<0.1s\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 88/88 26.2it/s 3.4s0.0s\n",
      "                   all       0.93          1\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\u001b[K      35/80       1.3G     0.1905         20        224: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 907/907 17.3it/s 52.5s<0.1s\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 88/88 26.5it/s 3.3s0.0s\n",
      "                   all      0.929          1\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\u001b[K      36/80       1.3G     0.1873         20        224: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 907/907 17.1it/s 53.1s<0.1s\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 88/88 26.3it/s 3.3s0.0s\n",
      "                   all      0.929          1\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\u001b[K      37/80       1.3G     0.1854         20        224: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 907/907 17.2it/s 52.7s<0.1s\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 88/88 26.3it/s 3.3s0.1s\n",
      "                   all      0.928          1\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\u001b[K      38/80       1.3G     0.1865         20        224: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 907/907 17.1it/s 53.1s<0.1s\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 88/88 26.4it/s 3.3s0.0s\n",
      "                   all      0.928          1\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\u001b[K      39/80       1.3G     0.1825         20        224: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 907/907 17.2it/s 52.6s<0.1s\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 88/88 26.5it/s 3.3s0.0s\n",
      "                   all      0.929          1\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\u001b[K      40/80       1.3G     0.1731         20        224: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 907/907 17.1it/s 53.1s<0.1s\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 88/88 26.4it/s 3.3s0.1s\n",
      "                   all      0.929          1\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\u001b[K      41/80       1.3G     0.1742         20        224: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 907/907 17.3it/s 52.5s<0.1s\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 88/88 26.1it/s 3.4s0.1s\n",
      "                   all       0.93          1\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\u001b[K      42/80       1.3G     0.1687         20        224: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 907/907 17.0it/s 53.3s<0.1s\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 88/88 26.6it/s 3.3s0.1s\n",
      "                   all      0.929          1\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\u001b[K      43/80       1.3G     0.1712         20        224: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 907/907 17.2it/s 52.6s<0.1s\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 88/88 26.6it/s 3.3s0.1s\n",
      "                   all       0.93          1\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\u001b[K      44/80       1.3G     0.1695         20        224: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 907/907 17.1it/s 53.2s<0.1s\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 88/88 26.5it/s 3.3s0.1s\n",
      "                   all       0.93          1\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\u001b[K      45/80       1.3G     0.1603         20        224: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 907/907 17.3it/s 52.5s<0.1s\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 88/88 26.3it/s 3.3s0.0s\n",
      "                   all      0.931          1\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\u001b[K      46/80       1.3G      0.164         20        224: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 907/907 17.1it/s 53.0s<0.1s\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 88/88 26.0it/s 3.4s0.0s\n",
      "                   all      0.931          1\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\u001b[K      47/80       1.3G     0.1548         20        224: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 907/907 17.2it/s 52.7s<0.1s\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 88/88 26.5it/s 3.3s0.0s\n",
      "                   all      0.931          1\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\u001b[K      48/80       1.3G     0.1549         20        224: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 907/907 17.0it/s 53.2s<0.1s\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 88/88 26.0it/s 3.4s0.1s\n",
      "                   all      0.932          1\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\u001b[K      49/80       1.3G     0.1566         20        224: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 907/907 17.2it/s 52.7s<0.1s\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 88/88 26.6it/s 3.3s0.0s\n",
      "                   all      0.931          1\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\u001b[K      50/80       1.3G     0.1459         20        224: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 907/907 17.1it/s 53.0s<0.1s\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 88/88 26.7it/s 3.3s0.0s\n",
      "                   all      0.932          1\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\u001b[K      51/80       1.3G     0.1417         20        224: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 907/907 17.2it/s 52.7s<0.1s\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 88/88 26.5it/s 3.3s0.0s\n",
      "                   all      0.932          1\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\u001b[K      52/80       1.3G     0.1389         20        224: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 907/907 17.1it/s 53.1s<0.1s\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 88/88 26.3it/s 3.3s0.0s\n",
      "                   all      0.933          1\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\u001b[K      53/80       1.3G     0.1393         20        224: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 907/907 17.2it/s 52.7s<0.1s\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 88/88 26.4it/s 3.3s0.1s\n",
      "                   all      0.933          1\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\u001b[K      54/80       1.3G     0.1336         20        224: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 907/907 17.1it/s 53.1s<0.1s\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 88/88 26.6it/s 3.3s0.0s\n",
      "                   all      0.934      0.999\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\u001b[K      55/80       1.3G      0.139         20        224: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 907/907 17.2it/s 52.6s<0.1s\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 88/88 26.4it/s 3.3s0.1s\n",
      "                   all      0.934      0.999\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\u001b[K      56/80       1.3G     0.1346         20        224: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 907/907 17.0it/s 53.3s<0.1s\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 88/88 26.5it/s 3.3s0.0s\n",
      "                   all      0.934      0.999\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\u001b[K      57/80       1.3G     0.1282         20        224: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 907/907 17.2it/s 52.7s<0.1s\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 88/88 26.3it/s 3.3s0.1s\n",
      "                   all      0.935      0.999\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\u001b[K      58/80       1.3G       0.12         20        224: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 907/907 17.1it/s 53.2s<0.1s\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 88/88 26.0it/s 3.4s0.1s\n",
      "                   all      0.935      0.999\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\u001b[K      59/80       1.3G     0.1152         20        224: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 907/907 17.2it/s 52.6s<0.1s\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 88/88 26.2it/s 3.4s0.0s\n",
      "                   all      0.936      0.999\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\u001b[K      60/80       1.3G     0.1182         20        224: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 907/907 17.1it/s 53.0s<0.1s\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 88/88 26.6it/s 3.3s0.0s\n",
      "                   all      0.936      0.999\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\u001b[K      61/80       1.3G     0.1146         20        224: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 907/907 17.2it/s 52.6s<0.1s\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 88/88 26.5it/s 3.3s0.0s\n",
      "                   all      0.936      0.999\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\u001b[K      62/80       1.3G     0.1089         20        224: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 907/907 17.0it/s 53.3s<0.1s\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 88/88 26.4it/s 3.3s0.1s\n",
      "                   all      0.936          1\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\u001b[K      63/80       1.3G     0.1016         20        224: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 907/907 17.1it/s 53.0s<0.2s\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 88/88 26.4it/s 3.3s0.0s\n",
      "                   all      0.936          1\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\u001b[K      64/80       1.3G     0.1048         20        224: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 907/907 16.8it/s 54.1s<0.2s\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 88/88 8.5it/s 10.4s<0.3s\n",
      "                   all      0.936          1\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\u001b[K      65/80       1.3G     0.1025         20        224: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 907/907 17.3it/s 52.4s<0.1s\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 88/88 18.1it/s 4.9s0.1s\n",
      "                   all      0.935          1\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\u001b[K      66/80       1.3G    0.09942         20        224: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 907/907 17.0it/s 53.2s<0.1s\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 88/88 26.6it/s 3.3s0.0s\n",
      "                   all      0.935          1\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\u001b[K      67/80       1.3G     0.0967         20        224: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 907/907 17.2it/s 52.7s<0.1s\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 88/88 26.6it/s 3.3s0.0s\n",
      "                   all      0.936          1\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\u001b[K      68/80       1.3G    0.09393         20        224: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 907/907 17.1it/s 53.0s<0.1s\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 88/88 26.4it/s 3.3s0.1s\n",
      "                   all      0.936          1\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\u001b[K      69/80       1.3G    0.08887         20        224: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 907/907 17.2it/s 52.8s<0.1s\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 88/88 26.3it/s 3.4s0.1s\n",
      "                   all      0.936          1\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\u001b[K      70/80       1.3G    0.08699         20        224: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 907/907 17.1it/s 53.1s<0.1s\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 88/88 26.2it/s 3.4s0.0s\n",
      "                   all      0.937          1\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\u001b[K      71/80       1.3G    0.08526         20        224: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 907/907 14.9it/s 1:01<0.2ss\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 88/88 16.0it/s 5.5s0.3s\n",
      "                   all      0.937          1\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\u001b[K      72/80       1.3G    0.08077         20        224: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 907/907 17.1it/s 52.9s<0.1s\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 88/88 25.1it/s 3.5s0.1s\n",
      "                   all      0.937          1\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\u001b[K      73/80       1.3G    0.07774         20        224: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 907/907 17.2it/s 52.7s<0.1s\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 88/88 26.2it/s 3.4s0.0s\n",
      "                   all      0.936          1\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\u001b[K      74/80       1.3G    0.07556         20        224: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 907/907 17.1it/s 52.9s<0.1s\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 88/88 26.3it/s 3.3s0.0s\n",
      "                   all      0.935          1\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\u001b[K      75/80       1.3G    0.07384         20        224: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 907/907 17.2it/s 52.7s<0.1s\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 88/88 26.3it/s 3.3s0.1s\n",
      "                   all      0.935          1\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\u001b[K      76/80       1.3G     0.0724         20        224: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 907/907 17.1it/s 53.0s<0.1s\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 88/88 26.1it/s 3.4s0.0s\n",
      "                   all      0.936          1\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\u001b[K      77/80       1.3G    0.06942         20        224: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 907/907 17.2it/s 52.7s<0.1s\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 88/88 26.4it/s 3.3s0.0s\n",
      "                   all      0.935          1\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\u001b[K      78/80       1.3G      0.065         20        224: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 907/907 17.1it/s 53.0s<0.1s\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 88/88 26.6it/s 3.3s0.1s\n",
      "                   all      0.935          1\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\u001b[K      79/80       1.3G    0.06443         20        224: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 907/907 17.3it/s 52.6s<0.1s\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 88/88 25.9it/s 3.4s0.0s\n",
      "                   all      0.935          1\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\u001b[K      80/80       1.3G    0.06221         20        224: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 907/907 17.1it/s 53.0s<0.1s\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 88/88 26.3it/s 3.3s0.1s\n",
      "                   all      0.935          1\n",
      "\n",
      "80 epochs completed in 1.281 hours.\n",
      "Optimizer stripped from F:\\shiii\\multidiciplinary\\intellisort\\runs\\classify\\model_work\\runs\\waste_classifier\\weights\\last.pt, 10.3MB\n",
      "Optimizer stripped from F:\\shiii\\multidiciplinary\\intellisort\\runs\\classify\\model_work\\runs\\waste_classifier\\weights\\best.pt, 10.3MB\n",
      "\n",
      "Validating F:\\shiii\\multidiciplinary\\intellisort\\runs\\classify\\model_work\\runs\\waste_classifier\\weights\\best.pt...\n",
      "Ultralytics 8.4.11  Python-3.10.11 torch-2.1.2+cu118 CUDA:0 (NVIDIA GeForce RTX 4050 Laptop GPU, 6140MiB)\n",
      "YOLOv8s-cls summary (fused): 30 layers, 5,084,167 parameters, 0 gradients, 12.5 GFLOPs\n",
      "\u001b[34m\u001b[1mtrain:\u001b[0m F:\\shiii\\multidiciplinary\\intellisort\\data\\combined_dataset\\train... found 29012 images in 7 classes  \n",
      "\u001b[34m\u001b[1mval:\u001b[0m F:\\shiii\\multidiciplinary\\intellisort\\data\\combined_dataset\\val... found 5607 images in 7 classes  \n",
      "\u001b[34m\u001b[1mtest:\u001b[0m F:\\shiii\\multidiciplinary\\intellisort\\data\\combined_dataset\\test... found 3068 images in 7 classes  \n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 88/88 24.3it/s 3.6s0.0s\n",
      "                   all      0.937          1\n",
      "Speed: 0.1ms preprocess, 0.5ms inference, 0.0ms loss, 0.0ms postprocess per image\n",
      "Results saved to \u001b[1mF:\\shiii\\multidiciplinary\\intellisort\\runs\\classify\\model_work\\runs\\waste_classifier\u001b[0m\n",
      "\n",
      "======================================================================\n",
      "‚úÖ TRAINING COMPLETE!\n",
      "======================================================================\n",
      "\n",
      "üíæ Models saved:\n",
      "   Best: F:\\shiii\\multidiciplinary\\intellisort\\runs\\classify\\model_work\\runs\\waste_classifier\\weights\\best.pt\n",
      "   Last: F:\\shiii\\multidiciplinary\\intellisort\\runs\\classify\\model_work\\runs\\waste_classifier\\weights\\last.pt\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"üöÄ STARTING TRAINING\")\n",
    "\n",
    "\n",
    "print(f\"\\nTraining on: {torch.cuda.get_device_name(0) if torch.cuda.is_available() else 'CPU'}\")\n",
    "print(f\"Images: 29,012 train / 5,607 val / 3,068 test\")\n",
    "print(f\"\\n‚è≥ Estimated time: 3-4 hours\")\n",
    "print(f\"üí° You can monitor GPU usage: nvidia-smi -l 1\\n\")\n",
    "\n",
    "# Create output directory\n",
    "output_dir = Path('model_work/runs')\n",
    "output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# TRAIN - with AMP disabled to avoid NumPy issue\n",
    "results = model.train(\n",
    "    # Data\n",
    "    data=str(dataset_path),\n",
    "    \n",
    "    # Training duration\n",
    "    epochs=EPOCHS,\n",
    "    patience=PATIENCE,\n",
    "    \n",
    "    # Image settings\n",
    "    imgsz=IMAGE_SIZE,\n",
    "    batch=BATCH_SIZE,\n",
    "    \n",
    "    # Device\n",
    "    device=0,\n",
    "    \n",
    "    # Learning rate (optimized for fine-tuning)\n",
    "    lr0=LEARNING_RATE,\n",
    "    lrf=0.01,\n",
    "    momentum=0.937,\n",
    "    weight_decay=0.0005,\n",
    "    \n",
    "    # Optimizer\n",
    "    optimizer='Adam',\n",
    "    \n",
    "    # Data augmentation\n",
    "    hsv_h=0.015,\n",
    "    hsv_s=0.7,\n",
    "    hsv_v=0.4,\n",
    "    degrees=10,\n",
    "    translate=0.1,\n",
    "    scale=0.5,\n",
    "    fliplr=0.5,\n",
    "    flipud=0.2,\n",
    "    mosaic=0.0,\n",
    "    \n",
    "    # Output\n",
    "    project='model_work/runs',\n",
    "    name='waste_classifier',\n",
    "    exist_ok=True,\n",
    "    \n",
    "    # Saving\n",
    "    save=True,\n",
    "    save_period=CHECKPOINT_FREQ,\n",
    "    \n",
    "    # Performance\n",
    "    workers=4,\n",
    "    amp=False,  # ‚Üê DISABLED to avoid NumPy error (15% slower but works)\n",
    "    \n",
    "    # Logging\n",
    "    verbose=True,\n",
    "    plots=True,\n",
    "    pretrained=True,\n",
    "    val=True,\n",
    ")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"‚úÖ TRAINING COMPLETE!\")\n",
    "\n",
    "\n",
    "# Save paths\n",
    "best_model_path = Path(results.save_dir) / 'weights' / 'best.pt'\n",
    "last_model_path = Path(results.save_dir) / 'weights' / 'last.pt'\n",
    "results_dir = Path(results.save_dir)\n",
    "\n",
    "globals()['best_model_path'] = best_model_path\n",
    "globals()['last_model_path'] = last_model_path\n",
    "globals()['results_dir'] = results_dir\n",
    "\n",
    "print(f\"\\nüíæ Models saved:\")\n",
    "print(f\"   Best: {best_model_path}\")\n",
    "print(f\"   Last: {last_model_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e831b2e",
   "metadata": {},
   "source": [
    "# Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9ff98481",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Config loaded!\n",
      "   Classes: ['plastic', 'glass', 'metal', 'paper', 'cardboard', 'organic', 'trash']\n",
      "   Dataset: data\\combined_dataset\n",
      "\n",
      "‚úÖ Model loaded: 10.3 MB\n",
      "..\\data\\combined_dataset\n",
      "\n",
      "‚úÖ Ready for evaluation!\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "from pathlib import Path\n",
    "from ultralytics import YOLO\n",
    "\n",
    "# Load config from exact location\n",
    "config_path = Path('dataset_config.pkl')\n",
    "\n",
    "with open(config_path, 'rb') as f:\n",
    "    config = pickle.load(f)\n",
    "\n",
    "print(\"‚úÖ Config loaded!\")\n",
    "print(f\"   Classes: {config['class_names']}\")\n",
    "print(f\"   Dataset: {config['dataset_path']}\")\n",
    "\n",
    "# Load model from exact location\n",
    "best_model_path = Path('best.pt')\n",
    "model = YOLO(best_model_path)\n",
    "\n",
    "print(f\"\\n‚úÖ Model loaded: {best_model_path.stat().st_size / 1e6:.1f} MB\")\n",
    "\n",
    "# Extract variables\n",
    "dataset_path = Path('../data/combined_dataset')\n",
    "class_names = config['class_names']\n",
    "print(dataset_path)\n",
    "# Set globals for next cells\n",
    "globals()['model'] = model\n",
    "globals()['dataset_path'] = dataset_path\n",
    "globals()['class_names'] = class_names\n",
    "globals()['config'] = config\n",
    "globals()['best_model_path'] = best_model_path\n",
    "\n",
    "print(\"\\n‚úÖ Ready for evaluation!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6f503bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "TEST SET VALIDATION\n",
      "======================================================================\n",
      "\n",
      "üìä Running comprehensive validation on test set...\n",
      "   Dataset: ..\\data\\combined_dataset\n",
      "   Test images: 3,068\n",
      "\n",
      "Ultralytics 8.4.11  Python-3.10.11 torch-2.1.2+cu118 CUDA:0 (NVIDIA GeForce RTX 4050 Laptop GPU, 6140MiB)\n",
      "YOLOv8s-cls summary (fused): 30 layers, 5,084,167 parameters, 0 gradients, 12.5 GFLOPs\n",
      "\u001b[34m\u001b[1mtrain:\u001b[0m F:\\shiii\\multidiciplinary\\intellisort\\data\\combined_dataset\\train... found 29012 images in 7 classes  \n",
      "\u001b[34m\u001b[1mval:\u001b[0m F:\\shiii\\multidiciplinary\\intellisort\\data\\combined_dataset\\val... found 5607 images in 7 classes  \n",
      "\u001b[34m\u001b[1mtest:\u001b[0m F:\\shiii\\multidiciplinary\\intellisort\\data\\combined_dataset\\test... found 3068 images in 7 classes  \n",
      "\u001b[34m\u001b[1mtest: \u001b[0mFast image access  (ping: 0.20.1 ms, read: 7.44.9 MB/s, size: 54.2 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mtest: \u001b[0mScanning F:\\shiii\\multidiciplinary\\intellisort\\data\\combined_dataset\\test... 3068 images, 0 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 3068/3068 928.4it/s 3.3s0.1s\n",
      "\u001b[34m\u001b[1mtest: \u001b[0mNew cache created: F:\\shiii\\multidiciplinary\\intellisort\\data\\combined_dataset\\test.cache\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 96/96 40.2it/s 2.4s0.1s\n",
      "                   all      0.945          1\n",
      "Speed: 0.1ms preprocess, 0.6ms inference, 0.0ms loss, 0.0ms postprocess per image\n",
      "Results saved to \u001b[1mF:\\shiii\\multidiciplinary\\intellisort\\model_work\\runs\\classify\\val3\u001b[0m\n",
      "\n",
      "======================================================================\n",
      "OVERALL TEST RESULTS\n",
      "======================================================================\n",
      "\n",
      "üéØ Accuracy Metrics:\n",
      "   Top-1 Accuracy: 0.9446 (94.46%)\n",
      "   Top-5 Accuracy: 1.0000 (100.00%)\n",
      "\n",
      "   Overall Rating: üåü EXCELLENT\n",
      "\n",
      "‚úÖ Test validation complete!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"TEST SET VALIDATION\")\n",
    "\n",
    "\n",
    "print(f\"\\nüìä Running comprehensive validation on test set...\")\n",
    "print(f\"   Dataset: {dataset_path}\")\n",
    "print(f\"   Test images: 3,068\\n\")\n",
    "\n",
    "# Run validation on test set\n",
    "test_results = model.val(\n",
    "    data=str(dataset_path),\n",
    "    split='test',\n",
    "    batch=32,\n",
    "    imgsz=224,\n",
    "    device=0,\n",
    "    plots=True,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"OVERALL TEST RESULTS\")\n",
    "\n",
    "\n",
    "print(f\"\\nüéØ Accuracy Metrics:\")\n",
    "print(f\"   Top-1 Accuracy: {test_results.top1:.4f} ({test_results.top1*100:.2f}%)\")\n",
    "print(f\"   Top-5 Accuracy: {test_results.top5:.4f} ({test_results.top5*100:.2f}%)\")\n",
    "\n",
    "# Performance rating\n",
    "if test_results.top1 >= 0.90:\n",
    "    rating = \"üåü EXCELLENT\"\n",
    "elif test_results.top1 >= 0.85:\n",
    "    rating = \"‚úÖ GOOD\"\n",
    "elif test_results.top1 >= 0.80:\n",
    "    rating = \"üëç ACCEPTABLE\"\n",
    "else:\n",
    "    rating = \"‚ö†Ô∏è NEEDS IMPROVEMENT\"\n",
    "\n",
    "print(f\"\\n   Overall Rating: {rating}\")\n",
    "\n",
    "# Save for later cells\n",
    "globals()['test_results'] = test_results\n",
    "\n",
    "print(\"\\n‚úÖ Test validation complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88c45db9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "DETAILED PER-CLASS ANALYSIS\n",
      "======================================================================\n",
      "\n",
      "üìä Analyzing 7 classes in detail...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "PER-CLASS PERFORMANCE REPORT\n",
      "======================================================================\n",
      "\n",
      "Category      Test Imgs    Top-1    Top-5   Avg Conf Status\n",
      "------------------------------------------------------------------------------------------\n",
      "cardboard           236    98.3%   100.0%      98.6%  üåü Excellent\n",
      "glass               354    97.7%   100.0%      97.4%  üåü Excellent\n",
      "metal               354    93.2%   100.0%      96.4%  ‚úÖ Great\n",
      "organic             354    99.2%   100.0%      98.9%  üåü Excellent\n",
      "paper               472    92.2%   100.0%      94.8%  ‚úÖ Great\n",
      "plastic             944    93.1%   100.0%      96.3%  ‚úÖ Great\n",
      "trash               354    91.8%   100.0%      95.2%  ‚úÖ Great\n",
      "------------------------------------------------------------------------------------------\n",
      "OVERALL           3,068    94.5%   100.0%\n",
      "==========================================================================================\n",
      "\n",
      "‚úÖ Per-class analysis complete!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "print(\"DETAILED PER-CLASS ANALYSIS\")\n",
    "\n",
    "\n",
    "test_path = dataset_path / 'test'\n",
    "\n",
    "# Data structures\n",
    "class_correct = defaultdict(int)\n",
    "class_total = defaultdict(int)\n",
    "class_predictions = defaultdict(lambda: defaultdict(int))\n",
    "class_confidences = defaultdict(list)\n",
    "class_top5_correct = defaultdict(int)\n",
    "\n",
    "print(f\"\\nüìä Analyzing {len(class_names)} classes in detail...\\n\")\n",
    "\n",
    "# Evaluate each class\n",
    "for cat in class_names:\n",
    "    cat_path = test_path / cat\n",
    "    if not cat_path.exists():\n",
    "        continue\n",
    "    \n",
    "    images = list(cat_path.glob('*.jpg')) + list(cat_path.glob('*.png'))\n",
    "    \n",
    "    for img_path in tqdm(images, desc=f\"Testing {cat:12s}\", leave=False):\n",
    "        try:\n",
    "            pred = model(img_path, verbose=False)\n",
    "            \n",
    "            # Get predictions\n",
    "            pred_class = pred[0].names[pred[0].probs.top1]\n",
    "            confidence = pred[0].probs.top1conf.item()\n",
    "            top5_classes = [pred[0].names[i] for i in pred[0].probs.top5]\n",
    "            \n",
    "            # Record\n",
    "            class_total[cat] += 1\n",
    "            class_predictions[cat][pred_class] += 1\n",
    "            class_confidences[cat].append(confidence)\n",
    "            \n",
    "            # Top-1 accuracy\n",
    "            if pred_class == cat:\n",
    "                class_correct[cat] += 1\n",
    "            \n",
    "            # Top-5 accuracy\n",
    "            if cat in top5_classes:\n",
    "                class_top5_correct[cat] += 1\n",
    "                \n",
    "        except Exception as e:\n",
    "            continue\n",
    "\n",
    "# Display results\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"PER-CLASS PERFORMANCE REPORT\")\n",
    "\n",
    "\n",
    "print(f\"\\n{'Category':<12} {'Test Imgs':>10} {'Top-1':>8} {'Top-5':>8} {'Avg Conf':>10} {'Status'}\")\n",
    "print(\"-\"*90)\n",
    "\n",
    "class_metrics = {}\n",
    "\n",
    "for cat in sorted(class_names):\n",
    "    if cat not in class_total or class_total[cat] == 0:\n",
    "        continue\n",
    "    \n",
    "    total = class_total[cat]\n",
    "    correct = class_correct[cat]\n",
    "    top5_correct = class_top5_correct[cat]\n",
    "    \n",
    "    # Metrics\n",
    "    top1_acc = (correct / total) * 100\n",
    "    top5_acc = (top5_correct / total) * 100\n",
    "    avg_conf = np.mean(class_confidences[cat]) * 100\n",
    "    \n",
    "    # Store\n",
    "    class_metrics[cat] = {\n",
    "        'total': total,\n",
    "        'correct': correct,\n",
    "        'top1_accuracy': top1_acc,\n",
    "        'top5_accuracy': top5_acc,\n",
    "        'avg_confidence': avg_conf\n",
    "    }\n",
    "    \n",
    "    # Status\n",
    "    if top1_acc >= 95:\n",
    "        status = \"üåü Excellent\"\n",
    "    elif top1_acc >= 90:\n",
    "        status = \"‚úÖ Great\"\n",
    "    elif top1_acc >= 85:\n",
    "        status = \"üëç Good\"\n",
    "    elif top1_acc >= 80:\n",
    "        status = \"‚ö†Ô∏è Fair\"\n",
    "    else:\n",
    "        status = \"‚ùå Poor\"\n",
    "    \n",
    "    print(f\"{cat:<12} {total:>10,} {top1_acc:>7.1f}% {top5_acc:>7.1f}% {avg_conf:>9.1f}%  {status}\")\n",
    "\n",
    "print(\"-\"*90)\n",
    "\n",
    "# Overall\n",
    "total_correct = sum(class_correct.values())\n",
    "total_images = sum(class_total.values())\n",
    "total_top5 = sum(class_top5_correct.values())\n",
    "overall_top1 = (total_correct / total_images) * 100\n",
    "overall_top5 = (total_top5 / total_images) * 100\n",
    "\n",
    "print(f\"{'OVERALL':<12} {total_images:>10,} {overall_top1:>7.1f}% {overall_top5:>7.1f}%\")\n",
    "print(\"=\"*90)\n",
    "\n",
    "# Save for later cells\n",
    "globals()['class_metrics'] = class_metrics\n",
    "globals()['class_correct'] = class_correct\n",
    "globals()['class_total'] = class_total\n",
    "globals()['class_predictions'] = class_predictions\n",
    "globals()['class_confidences'] = class_confidences\n",
    "\n",
    "print(\"\\n‚úÖ Per-class analysis complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6292997f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "CONFUSION ANALYSIS\n",
      "======================================================================\n",
      "\n",
      "üìä Most Common Misclassifications:\n",
      "\n",
      "True Class   ‚Üí Predicted As    Count     Rate\n",
      "----------------------------------------------------------------------\n",
      "trash        ‚Üí paper              15x     4.2%\n",
      "paper        ‚Üí plastic            15x     3.2%\n",
      "plastic      ‚Üí paper              22x     2.3%\n",
      "metal        ‚Üí paper               8x     2.3%\n",
      "glass        ‚Üí plastic             6x     1.7%\n",
      "cardboard    ‚Üí paper               3x     1.3%\n",
      "\n",
      "üí° These are the class pairs the model confuses most\n",
      "\n",
      "‚ö†Ô∏è Confusion matrix image not found\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"CONFUSION ANALYSIS\")\n",
    "\n",
    "\n",
    "print(f\"\\nüìä Most Common Misclassifications:\\n\")\n",
    "\n",
    "confusion_pairs = []\n",
    "\n",
    "for true_cat in sorted(class_names):\n",
    "    if true_cat not in class_predictions or class_total[true_cat] == 0:\n",
    "        continue\n",
    "    \n",
    "    predictions = class_predictions[true_cat].copy()\n",
    "    predictions.pop(true_cat, None)  # Remove correct predictions\n",
    "    \n",
    "    if predictions:\n",
    "        # Find most common mistake\n",
    "        most_confused = max(predictions.items(), key=lambda x: x[1])\n",
    "        confusion_rate = (most_confused[1] / class_total[true_cat]) * 100\n",
    "        \n",
    "        if confusion_rate > 1:  # Show if >1% confusion\n",
    "            confusion_pairs.append((true_cat, most_confused[0], most_confused[1], confusion_rate))\n",
    "\n",
    "# Sort by confusion rate\n",
    "confusion_pairs.sort(key=lambda x: x[3], reverse=True)\n",
    "\n",
    "if confusion_pairs:\n",
    "    print(f\"{'True Class':<12} {'‚Üí'} {'Predicted As':<12} {'Count':>8} {'Rate':>8}\")\n",
    "    print(\"-\"*70)\n",
    "    \n",
    "    for true_cat, pred_cat, count, rate in confusion_pairs:\n",
    "        print(f\"{true_cat:<12} ‚Üí {pred_cat:<12} {count:>8}x {rate:>7.1f}%\")\n",
    "    \n",
    "    print(\"\\nüí° These are the class pairs the model confuses most\")\n",
    "else:\n",
    "    print(\"‚úÖ No significant confusion between classes!\")\n",
    "\n",
    "# Display confusion matrix\n",
    "from IPython.display import Image, display\n",
    "\n",
    "# Find confusion matrix from latest validation\n",
    "val_dirs = sorted(Path('model_work/runs/classify').glob('val*'), reverse=True)\n",
    "\n",
    "confusion_img = None\n",
    "for val_dir in val_dirs:\n",
    "    candidate = val_dir / 'confusion_matrix_normalized.png'\n",
    "    if candidate.exists():\n",
    "        confusion_img = candidate\n",
    "        break\n",
    "\n",
    "if confusion_img:\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"CONFUSION MATRIX (NORMALIZED)\")\n",
    "    \n",
    "    print(f\"\\nLocation: {confusion_img}\\n\")\n",
    "    display(Image(filename=str(confusion_img)))\n",
    "else:\n",
    "    print(\"\\n‚ö†Ô∏è Confusion matrix image not found\")\n",
    "\n",
    "# Save confusion pairs\n",
    "globals()['confusion_pairs'] = confusion_pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84ac8fc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "SAMPLE PREDICTIONS FROM EACH CLASS\n",
      "======================================================================\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 2100x900 with 21 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úÖ Sample predictions shown\n",
      "   üü¢ Green = Correct\n",
      "   üî¥ Red = Incorrect\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "\n",
    "\n",
    "print(\"SAMPLE PREDICTIONS FROM EACH CLASS\")\n",
    "\n",
    "\n",
    "# Show 3 samples per class\n",
    "fig, axes = plt.subplots(3, 7, figsize=(21, 9))\n",
    "\n",
    "for col, cat in enumerate(sorted(class_names)):\n",
    "    cat_path = test_path / cat\n",
    "    \n",
    "    if not cat_path.exists():\n",
    "        continue\n",
    "    \n",
    "    images = list(cat_path.glob('*.jpg')) + list(cat_path.glob('*.png'))\n",
    "    \n",
    "    if len(images) == 0:\n",
    "        continue\n",
    "    \n",
    "    # Take 3 random samples\n",
    "    samples = random.sample(images, min(3, len(images)))\n",
    "    \n",
    "    for row, img_path in enumerate(samples):\n",
    "        img = cv2.imread(str(img_path))\n",
    "        \n",
    "        if img is not None:\n",
    "            img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "            \n",
    "            # Predict\n",
    "            pred = model(img_path, verbose=False)\n",
    "            pred_class = pred[0].names[pred[0].probs.top1]\n",
    "            confidence = pred[0].probs.top1conf.item()\n",
    "            \n",
    "            # Display\n",
    "            axes[row, col].imshow(img_rgb)\n",
    "            axes[row, col].axis('off')\n",
    "            \n",
    "            # Color based on correctness\n",
    "            is_correct = (pred_class == cat)\n",
    "            color = 'green' if is_correct else 'red'\n",
    "            symbol = '‚úì' if is_correct else '‚úó'\n",
    "            \n",
    "            title = f\"{symbol} {cat}\\n‚Üí {pred_class}\\n{confidence:.0%}\"\n",
    "            axes[row, col].set_title(title, fontsize=8, color=color, fontweight='bold')\n",
    "\n",
    "plt.suptitle('Sample Predictions Per Class', fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n‚úÖ Sample predictions shown\")\n",
    "print(\"   üü¢ Green = Correct\")\n",
    "print(\"   üî¥ Red = Incorrect\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69b46d70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "üéâ FINAL EVALUATION REPORT\n",
      "======================================================================\n",
      "\n",
      "üìä OVERALL PERFORMANCE:\n",
      "   Test Images:       3,068\n",
      "   Top-1 Accuracy:    94.46%\n",
      "   Top-5 Accuracy:    100.00%\n",
      "   Total Correct:     2,898\n",
      "   Total Errors:      170 (5.5%)\n",
      "\n",
      "üèÜ BEST PERFORMING CLASSES:\n",
      "   1. organic     : 99.15% (avg conf: 98.9%)\n",
      "   2. cardboard   : 98.31% (avg conf: 98.6%)\n",
      "   3. glass       : 97.74% (avg conf: 97.4%)\n",
      "\n",
      "üìâ CLASSES NEEDING ATTENTION:\n",
      "   1. trash       : 91.81% (avg conf: 95.2%)\n",
      "   2. paper       : 92.16% (avg conf: 94.8%)\n",
      "   3. plastic     : 93.11% (avg conf: 96.3%)\n",
      "\n",
      "üí™ MODEL STRENGTHS:\n",
      "   ‚Ä¢ Excellent (‚â•95%): cardboard, glass, organic\n",
      "   ‚Ä¢ Great (90-95%): metal, paper, plastic, trash\n",
      "   ‚Ä¢ Top-5 accuracy: 100.0% (perfect!)\n",
      "   ‚Ä¢ Overall accuracy exceeds 90% threshold\n",
      "\n",
      "üîç CONFUSION PATTERNS:\n",
      "   Top 3 confusion pairs:\n",
      "   1. trash ‚Üí paper: 15x (4.2%)\n",
      "   2. paper ‚Üí plastic: 15x (3.2%)\n",
      "   3. plastic ‚Üí paper: 22x (2.3%)\n",
      "\n",
      "‚úÖ DEPLOYMENT READINESS:\n",
      "   üü¢ PRODUCTION READY ‚úì\n",
      "   ‚Ä¢ All classes ‚â•85% accuracy\n",
      "   ‚Ä¢ Overall accuracy: 94.5%\n",
      "   ‚Ä¢ Lowest class: 91.8%\n",
      "\n",
      "üíæ Comprehensive report saved:\n",
      "   models\\evaluation_report.json\n",
      "   Size: 3.8 KB\n",
      "   models\\evaluation_summary.txt\n",
      "\n",
      "======================================================================\n",
      "üéâ EVALUATION COMPLETE!\n",
      "======================================================================\n",
      "\n",
      "üìã Summary:\n",
      "   ‚úÖ Model achieves 94.5% accuracy\n",
      "   ‚úÖ All 7 classes evaluated\n",
      "   ‚úÖ Ready for deployment: PRODUCTION_READY\n",
      "   ‚úÖ Reports saved in models/ directory\n",
      "\n",
      "üöÄ Next Steps:\n",
      "   1. Review confusion matrix and sample predictions\n",
      "   2. Integrate model with Flask backend\n",
      "   3. Connect to React frontend\n",
      "   4. Deploy to production!\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"üéâ FINAL EVALUATION REPORT\")\n",
    "\n",
    "\n",
    "print(f\"\\nüìä OVERALL PERFORMANCE:\")\n",
    "print(f\"   Test Images:       {total_images:,}\")\n",
    "print(f\"   Top-1 Accuracy:    {overall_top1:.2f}%\")\n",
    "print(f\"   Top-5 Accuracy:    {overall_top5:.2f}%\")\n",
    "print(f\"   Total Correct:     {total_correct:,}\")\n",
    "print(f\"   Total Errors:      {total_images - total_correct:,} ({(total_images - total_correct)/total_images*100:.1f}%)\")\n",
    "\n",
    "print(f\"\\nüèÜ BEST PERFORMING CLASSES:\")\n",
    "best_classes = sorted(class_metrics.items(), key=lambda x: x[1]['top1_accuracy'], reverse=True)[:3]\n",
    "for i, (cat, metrics) in enumerate(best_classes, 1):\n",
    "    print(f\"   {i}. {cat:12s}: {metrics['top1_accuracy']:.2f}% (avg conf: {metrics['avg_confidence']:.1f}%)\")\n",
    "\n",
    "print(f\"\\nüìâ CLASSES NEEDING ATTENTION:\")\n",
    "worst_classes = sorted(class_metrics.items(), key=lambda x: x[1]['top1_accuracy'])[:3]\n",
    "for i, (cat, metrics) in enumerate(worst_classes, 1):\n",
    "    print(f\"   {i}. {cat:12s}: {metrics['top1_accuracy']:.2f}% (avg conf: {metrics['avg_confidence']:.1f}%)\")\n",
    "\n",
    "print(f\"\\nüí™ MODEL STRENGTHS:\")\n",
    "excellent = [cat for cat, m in class_metrics.items() if m['top1_accuracy'] >= 95]\n",
    "great = [cat for cat, m in class_metrics.items() if 90 <= m['top1_accuracy'] < 95]\n",
    "\n",
    "if excellent:\n",
    "    print(f\"   ‚Ä¢ Excellent (‚â•95%): {', '.join(excellent)}\")\n",
    "if great:\n",
    "    print(f\"   ‚Ä¢ Great (90-95%): {', '.join(great)}\")\n",
    "print(f\"   ‚Ä¢ Top-5 accuracy: {overall_top5:.1f}% (perfect!)\")\n",
    "print(f\"   ‚Ä¢ Overall accuracy exceeds 90% threshold\")\n",
    "\n",
    "print(f\"\\nüîç CONFUSION PATTERNS:\")\n",
    "if confusion_pairs:\n",
    "    print(f\"   Top 3 confusion pairs:\")\n",
    "    for i, (true_cat, pred_cat, count, rate) in enumerate(confusion_pairs[:3], 1):\n",
    "        print(f\"   {i}. {true_cat} ‚Üí {pred_cat}: {count}x ({rate:.1f}%)\")\n",
    "else:\n",
    "    print(f\"   ‚Ä¢ No significant confusion!\")\n",
    "\n",
    "print(f\"\\n‚úÖ DEPLOYMENT READINESS:\")\n",
    "min_accuracy = min(m['top1_accuracy'] for m in class_metrics.values())\n",
    "\n",
    "if overall_top1 >= 90 and min_accuracy >= 85:\n",
    "    print(f\"   üü¢ PRODUCTION READY ‚úì\")\n",
    "    print(f\"   ‚Ä¢ All classes ‚â•85% accuracy\")\n",
    "    print(f\"   ‚Ä¢ Overall accuracy: {overall_top1:.1f}%\")\n",
    "    print(f\"   ‚Ä¢ Lowest class: {min_accuracy:.1f}%\")\n",
    "    deployment_status = \"PRODUCTION_READY\"\n",
    "elif overall_top1 >= 85:\n",
    "    print(f\"   üü° READY WITH MONITORING\")\n",
    "    print(f\"   ‚Ä¢ Monitor performance on weak classes\")\n",
    "    deployment_status = \"READY_WITH_MONITORING\"\n",
    "else:\n",
    "    print(f\"   üî¥ NEEDS IMPROVEMENT\")\n",
    "    deployment_status = \"NEEDS_IMPROVEMENT\"\n",
    "\n",
    "# Create comprehensive report\n",
    "report = {\n",
    "    'metadata': {\n",
    "        'model_path': str(best_model_path),\n",
    "        'model_type': 'YOLOv8s-cls',\n",
    "        'evaluation_date': datetime.now().isoformat(),\n",
    "        'dataset': str(dataset_path),\n",
    "        'deployment_status': deployment_status\n",
    "    },\n",
    "    'overall_metrics': {\n",
    "        'total_test_images': int(total_images),\n",
    "        'top1_accuracy': float(overall_top1 / 100),\n",
    "        'top5_accuracy': float(overall_top5 / 100),\n",
    "        'total_correct': int(total_correct),\n",
    "        'total_errors': int(total_images - total_correct),\n",
    "        'error_rate': float((total_images - total_correct) / total_images)\n",
    "    },\n",
    "    'per_class_metrics': {\n",
    "        cat: {\n",
    "            'test_images': int(metrics['total']),\n",
    "            'correct_predictions': int(metrics['correct']),\n",
    "            'top1_accuracy': float(metrics['top1_accuracy'] / 100),\n",
    "            'top5_accuracy': float(metrics['top5_accuracy'] / 100),\n",
    "            'avg_confidence': float(metrics['avg_confidence'] / 100)\n",
    "        }\n",
    "        for cat, metrics in class_metrics.items()\n",
    "    },\n",
    "    'confusion_analysis': [\n",
    "        {\n",
    "            'true_class': true_cat,\n",
    "            'predicted_as': pred_cat,\n",
    "            'count': int(count),\n",
    "            'confusion_rate': float(rate / 100)\n",
    "        }\n",
    "        for true_cat, pred_cat, count, rate in confusion_pairs\n",
    "    ],\n",
    "    'disposal_mapping': config.get('disposal_info', {})\n",
    "}\n",
    "\n",
    "# Save JSON report\n",
    "report_path = Path('models/evaluation_report.json')\n",
    "report_path.parent.mkdir(exist_ok=True)\n",
    "\n",
    "with open(report_path, 'w') as f:\n",
    "    json.dump(report, f, indent=2)\n",
    "\n",
    "print(f\"\\nüíæ Comprehensive report saved:\")\n",
    "print(f\"   {report_path}\")\n",
    "print(f\"   Size: {report_path.stat().st_size / 1024:.1f} KB\")\n",
    "\n",
    "# Also save a summary text file\n",
    "summary_path = Path('models/evaluation_summary.txt')\n",
    "\n",
    "with open(summary_path, 'w') as f:\n",
    "    f.write(\"=\"*70 + \"\\n\")\n",
    "    f.write(\"WASTE CLASSIFIER - EVALUATION SUMMARY\\n\")\n",
    "    f.write(\"=\"*70 + \"\\n\\n\")\n",
    "    f.write(f\"Model: YOLOv8s-cls\\n\")\n",
    "    f.write(f\"Date: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\\n\")\n",
    "    f.write(f\"Overall Accuracy: {overall_top1:.2f}%\\n\")\n",
    "    f.write(f\"Deployment Status: {deployment_status}\\n\\n\")\n",
    "    \n",
    "    f.write(\"Per-Class Performance:\\n\")\n",
    "    f.write(\"-\"*70 + \"\\n\")\n",
    "    for cat in sorted(class_names):\n",
    "        if cat in class_metrics:\n",
    "            m = class_metrics[cat]\n",
    "            f.write(f\"  {cat:12s}: {m['top1_accuracy']:5.1f}% (conf: {m['avg_confidence']:5.1f}%)\\n\")\n",
    "\n",
    "print(f\"   {summary_path}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"üéâ EVALUATION COMPLETE!\")\n",
    "\n",
    "\n",
    "print(\"\\nüìã Summary:\")\n",
    "print(f\"   ‚úÖ Model achieves {overall_top1:.1f}% accuracy\")\n",
    "print(f\"   ‚úÖ All {len(class_names)} classes evaluated\")\n",
    "print(f\"   ‚úÖ Ready for deployment: {deployment_status}\")\n",
    "print(f\"   ‚úÖ Reports saved in models/ directory\")\n",
    "\n",
    "print(\"\\nüöÄ Next Steps:\")\n",
    "print(\"   1. Review confusion matrix and sample predictions\")\n",
    "print(\"   2. Integrate model with Flask backend\")\n",
    "print(\"   3. Connect to React frontend\")\n",
    "print(\"   4. Deploy to production!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
